import streamlit as st
import requests
from azure.storage.blob import BlobServiceClient
from openai import AzureOpenAI
import tempfile, os, docx

# Azure ì„¤ì • ë³€ìˆ˜
search_service_name = None
search_api_key = None
index_name = "basic"
blob_service_client = None
gpt_client = None
deployment_name = None
lang_search_key = None

def init_blob_service_d(client: BlobServiceClient):
    global blob_service_client
    blob_service_client = client

def init_serach_d(service_name, api_key):
    global search_service_name, search_api_key
    search_service_name = service_name
    search_api_key = api_key

def init_gpt_d(endpoint, key, deployment):
    global gpt_client, deployment_name
    # gpt_client = AzureOpenAI(api_key=key, api_version="2024-07-18-preview", azure_endpoint=endpoint)
    # gpt_client = AzureOpenAI(api_key=key, api_version="2024-07-18", azure_endpoint=endpoint)
    gpt_client = AzureOpenAI(api_key=key, api_version="2024-04-01-preview", azure_endpoint=endpoint)
    deployment_name = deployment

def init_get_key(lang_key):
    global lang_search_key
    lang_search_key = lang_key

def ai_tab():
    st.header("ğŸŒ LangSearch + ë¬¸ì„œ ê¸°ë°˜ GPT ë¶„ì„ (RAG êµ¬ì¡°)")

    # í´ë¼ì´ì–¸íŠ¸ ì²´í¬
    if not blob_service_client or not gpt_client:
        st.error("í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜")
        return

    # RFP ë¬¸ì„œ ì„ íƒ
    container_client = blob_service_client.get_container_client("word-data")
    docx_files = [blob.name for blob in container_client.list_blobs() if blob.name.endswith(".docx")]

    if not docx_files:
        st.warning("ğŸ“ ì—…ë¡œë“œëœ RFP ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    selected_file = st.selectbox("ğŸ“„ ìš”ì•½í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”", docx_files)
    
    user_prompt = st.text_area("GPTì—ê²Œ ìš”ì²­í•  ì‘ì—… ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", 
        value="1. ì „ì²´ ë‚´ìš©ì„ ê°„ê²°í•œ í•œ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n" \
            "2. ë¬¸ì„œì— ì–¸ê¸‰ëœ í•µì‹¬ ì£¼ì œ ë˜ëŠ” ë„ë©”ì¸ì„ ë„ì¶œí•˜ê³  ì •ë¦¬í•˜ì„¸ìš”.\n" \
            "3. ì œì•ˆìš”ì²­ì˜ ëª©ì ê³¼ ë°°ê²½ì„ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.\n" \
            "4. ì—…ë¬´ì  ìš”êµ¬ì‚¬í•­ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìì²´ì ìœ¼ë¡œ í•­ëª©ì„ ë§Œë“¤ì–´ êµ¬ë¶„ëœ ì¡°ê²¬í‘œ í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n" \
            "5. ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ì„ ê¸°ëŠ¥/ë¹„ê¸°ëŠ¥/ìš´ì˜/ë³´ì•ˆì™€ ìì²´ì ìœ¼ë¡œ í•­ëª©ì„ ë§Œë“¤ì–´ í•­ëª©ë³„ë¡œ êµ¬ë¶„ëœ ì¡°ê²¬í‘œ í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n" \
            "6. ì´ ë¬¸ì„œì˜ íë¦„ì— ë§ì¶° ì˜ˆìƒë˜ëŠ” ëª©ì°¨ êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ì„¸ìš” (ì˜ˆ: ê°œìš” â†’ ìš”êµ¬ì‚¬í•­ â†’ ì œì•ˆì„œ êµ¬ì„±).\n" \
            "7. ì í•©í•œ IT ê¸°ìˆ  ë˜ëŠ” ìœ ê´€ ì†”ë£¨ì…˜ ì¤‘ ë³¸ ë¬¸ì„œì˜ ìš”êµ¬ì‚¬í•­ê³¼ ì—°ê´€ëœ ì¶”ì²œ ê¸°ìˆ ì„ ì œì‹œí•´ì£¼ì„¸ìš”.\n" \
            "8. ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•´ ë¬¸ì„œì˜ ì´í•´ë„ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”.",
        height=150
    )
    keyword = st.text_input("ğŸŒ ì™¸ë¶€ ì •ë³´ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ê¸ˆìœµ")
    # langsearch_api_key = st.text_input("ğŸ”‘ LangSearch API í‚¤ ì…ë ¥", type="password")
    langsearch_api_key = lang_search_key

    # í”„ë¡¬í”„íŠ¸ ì…ë ¥ & ì™¸ë¶€ ê²€ìƒ‰ì–´
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", key="rag_analysis_button"):        
        try:
            # ğŸ”½ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
            blob = blob_service_client.get_blob_client("word-data", selected_file)
            with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
                tmp.write(blob.download_blob().readall())
                tmp_path = tmp.name

            doc = docx.Document(tmp_path)
            paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
            document_text = "\n".join(paragraphs)
            os.remove(tmp_path)

            st.success("âœ… ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
            st.write(f"ğŸ“ ë¬¸ì„œ ê¸¸ì´: {len(document_text)}ì")

            # ğŸŒ LangSearch ê²€ìƒ‰ (POST ë°©ì‹)
            external_info = ""
            try:
                headers = {
                    "Authorization": f"Bearer {langsearch_api_key}",
                    "Content-Type": "application/json"
                }
                body = {
                    "query": keyword,
                    "freshness": "noLimit",
                    "summary": True,
                    "count": 5
                }
                resp = requests.post("https://api.langsearch.com/v1/web-search", headers=headers, json=body)
                if resp.status_code == 200:
                    results = resp.json().get("results", [])
                    external_info = "\n".join([r.get("summary", "") for r in results])
                    st.info(f"ğŸŒ ì™¸ë¶€ ì •ë³´ {len(results)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    st.warning(f"LangSearch ì‹¤íŒ¨: ìƒíƒœì½”ë“œ {resp.status_code}")
            except Exception as e:
                st.error(f"LangSearch í˜¸ì¶œ ì˜¤ë¥˜: {e}")

            # ğŸ¤– GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            gpt_prompt = f"""
                ë‹¹ì‹ ì€ ê¸ˆìœµ RFPë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì•„ë˜ëŠ” ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:
                \"\"\"{document_text}\"\"\"
                ì•„ë˜ëŠ” ì™¸ë¶€ ê²€ìƒ‰ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°°ê²½ ì •ë³´ì…ë‹ˆë‹¤:
                \"\"\"{external_info}\"\"\"
                ì‚¬ìš©ì ìš”ì²­:
                {user_prompt}
                ì „ì²´ ë¬¸ì„œì™€ ì™¸ë¶€ ë°°ê²½ì„ ë°˜ì˜í•˜ì—¬ step-by-stepìœ¼ë¡œ ë¶„ì„í•˜ê³  ì‘ë‹µí•˜ì„¸ìš”.
                """

            with st.expander("ğŸ“¨ GPT í”„ë¡¬í”„íŠ¸ í™•ì¸", expanded=False):
                st.code(gpt_prompt[:1200] + "..." if len(gpt_prompt) > 1200 else gpt_prompt)

            developer = """
                ë„ˆëŠ” ê¸ˆìœµê¶Œ RFP ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.  
                - ê¸ˆìœµ IT ì‹œìŠ¤í…œ, ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ, ê·œì œ í™˜ê²½ì— ì •í†µí•˜ë‹¤.  
                - RFP ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ ë¶„ì„í•´, ì‹¤í˜„ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ê³¼ ëª…í™•í•œ ê·¼ê±°ë¥¼ ì œì‹œí•œë‹¤.  
                - ì œì•ˆì„œëŠ” ë…¼ë¦¬ì  êµ¬ì¡°(ìš”êµ¬ì‚¬í•­, ì†”ë£¨ì…˜, ì¼ì •, ì˜ˆì‚°, ë¦¬ìŠ¤í¬ ë“±)ë¡œ ì‘ì„±í•˜ë©°, ê·¼ê±°ì™€ ë°ì´í„°, í‘œë¥¼ í™œìš©í•´ ì‹ ë¢°ë„ë¥¼ ë†’ì¸ë‹¤.  
                - ë³µì¡í•œ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…í•˜ê³ , í—ˆìœ„Â·ê³¼ì¥Â·ë¹„í˜„ì‹¤ì  ë‚´ìš©ì€ ë°°ì œí•œë‹¤.  
                - ë²•ì Â·ìœ¤ë¦¬ì  ê¸°ì¤€ê³¼ ê¸ˆìœµ ê·œì œë¥¼ ìµœëŒ€í•œ ì¤€ìˆ˜í•œë‹¤.  
                - ê°€ëŠ¥í•˜ë‹¤ë©´ ì‹¤ì œ ê¸ˆìœµê¶Œ RFP ì‚¬ë¡€ë¥¼ ì°¸ê³ í•´ ì„¤ë“ë ¥ ìˆëŠ” ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ë¼.
            """

            # ğŸ§  GPT í˜¸ì¶œ
            gpt_response = gpt_client.chat.completions.create(
                model=deployment_name,
                messages=[
                    {"role": "system", "content": developer},
                    {"role": "user", "content": gpt_prompt}
                ]
            )            

            if gpt_response:
                with st.expander("ğŸ“Œ GPT ë¶„ì„ ê²°ê³¼", expanded=False):
                    if gpt_response:
                        content = gpt_response.choices[0].message.content.strip()
                        st.markdown(content if content else "ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”.")
                    else:
                        st.error("GPT ì‘ë‹µ ì‹¤íŒ¨")
            else:
                st.error("GPT í˜¸ì¶œ ì‹¤íŒ¨")

            st.session_state.document_text = document_text
            st.session_state.external_info = external_info

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ì´ˆê¸° ì„¤ì •        
    # if "chat_input" not in st.session_state:
    #     st.session_state.chat_input = ""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    if "document_text" in st.session_state and "external_info" in st.session_state:
        st.subheader("ğŸ’¬ ChatBot ëŒ€í™”")     

        # ì§ˆë¬¸ ì…ë ¥ UI
        chat_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="chat_input")

        if st.button("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", key="chat_langsearch_button"):
            question = st.session_state["chat_input"].strip()
            if question:
                chat_prompt = f"ë¬¸ì„œ: {st.session_state.document_text}\nì™¸ë¶€ì •ë³´: {st.session_state.external_info}\nì§ˆë¬¸: {question}"
                chat_response = gpt_client.chat.completions.create(
                    model=deployment_name,
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ê¸ˆìœµ RFP ë¶„ì„ ì „ë¬¸ê°€ì´ë©°, ë¬¸ì„œì™€ ì™¸ë¶€ ì •ë³´ë¥¼ í•¨ê»˜ í™œìš©í•´ ë‹µë³€í•´ìš”."},
                        {"role": "user", "content": chat_prompt}
                    ]
                )
                if chat_response:
                    response_text = chat_response.choices[0].message.content.strip()
                    # íˆìŠ¤í† ë¦¬ ì €ì¥
                    st.session_state.chat_history.append({
                        "question": question,
                        "answer": response_text
                    })
                else:
                    st.warning("Chat ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ìš”.")

    # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    #   ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    st.markdown("---")
    st.markdown("### ğŸ—¨ï¸ ëŒ€í™” ê¸°ë¡")
    for idx, qa in enumerate(st.session_state.chat_history[::-1]):  # ìµœì‹  ìˆœ
        st.markdown(f"**ğŸŸ¢ ì§ˆë¬¸ {len(st.session_state.chat_history) - idx}:** {qa['question']}")
        st.markdown(f"**ğŸ§  ë‹µë³€:** {qa['answer']}")
        st.markdown("---")  # êµ¬ë¶„ì„ ìœ¼ë¡œ ë©”ì‹œì§€ ì •ë¦¬

    
